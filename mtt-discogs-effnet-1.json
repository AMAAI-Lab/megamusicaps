{
    "name": "MagnaTagATune",
    "type": "multi-label classifier",
    "link": "https://essentia.upf.edu/models/classification-heads/mtt/mtt-discogs-effnet-1.pb",
    "version": "1",
    "description": "classification of music by the MagnaTagATune's top-50 tags from discogs-effnet embeddings",
    "author": "Pablo Alonso",
    "email": "pablo.alonso@upf.edu",
    "release_date": "2022-11-20",
    "framework": "tensorflow",
    "framework_version": "2.8.0",
    "classes": [
        "ambient",
        "beat",
        "beats",
        "cello",
        "choir",
        "choral",
        "classic",
        "classical",
        "country",
        "dance",
        "drums",
        "electronic",
        "fast",
        "female",
        "female vocal",
        "female voice",
        "flute",
        "guitar",
        "harp",
        "harpsichord",
        "indian",
        "loud",
        "male",
        "male vocal",
        "male voice",
        "man",
        "metal",
        "new age",
        "no vocal",
        "no vocals",
        "no voice",
        "opera",
        "piano",
        "pop",
        "quiet",
        "rock",
        "singing",
        "sitar",
        "slow",
        "soft",
        "solo",
        "strings",
        "synth",
        "techno",
        "violin",
        "vocal",
        "vocals",
        "voice",
        "weird",
        "woman"
    ],
    "model_types": [
        "frozen_model"
    ],
    "dataset": {
        "name": "The MagnaTagATune",
        "size": "25,863 30-second excerpts",
        "metrics": {
            "test PR-AUC": 0.37,
            "test ROC-AUC": 0.9
        }
    },
    "schema": {
        "inputs": [
            {
                "name": "model/Placeholder",
                "type": "float",
                "shape": [
                    1280
                ]
            }
        ],
        "outputs": [
            {
                "name": "model/Sigmoid",
                "type": "float",
                "shape": [
                    50
                ],
                "op": "Sigmoid",
                "output_purpose": "predictions"
            },
            {
                "name": "model/dense_1/BiasAdd",
                "type": "float",
                "shape": [
                    50
                ],
                "op": "fully connected",
                "description": "logits",
                "output_purpose": ""
            },
            {
                "name": "model/dense/BiasAdd",
                "type": "float",
                "shape": [
                    512
                ],
                "op": "fully connected",
                "description": "penultimate layer",
                "output_purpose": ""
            }
        ]
    },
    "citation": "@inproceedings{alonso2022music,\n  title={Music Representation Learning Based on Editorial Metadata from Discogs},\n  author={Alonso-Jim{\\'e}nez, Pablo and Serra, Xavier and Bogdanov, Dmitry},\n  booktitle={Conference of the International Society for Music Information Retrieval (ISMIR)},\n  year={2022}\n}",
    "inference": {
        "sample_rate": 16000,
        "algorithm": "TensorflowPredict2D",
        "embedding_model": {
            "algorithm": "TensorflowPredictEffnetDiscogs",
            "model_name": "discogs-effnet-bs64-1",
            "link": "https://essentia.upf.edu/models/music-style-classification/discogs-effnet/discogs-effnet-bs64-1.pb"
        }
    }
}